# 에이전트
에이전트는 환경의 상태를 인식하고 그에 따라 행동하는 의사결정의 주체이다. 
동시에 강화학습의 대상이기 때문에 ➊ 환경과의 상호작용 ➋ 데이터셋 관리 
➌ 정책과 가치 함수 모델 관리 ➍ 정책의 평가와 개선과 같은 기능을 수행한다. 
이를 위해 에이전트는 환경과의 상호작용을 대리하는 액터와 함께 데이터셋, 네트워크, 학습자를 서브 모듈로 두고 있다.

## 1. 디렉토리 구성
| 파일 이름                  | 설명                        |
|:-----------------------|:--------------------------|
| `__init__.py`	          | 강화학습 프레임워크에서 제공하는 에이전트 레지스트리를 정의하고 있다. 에이전트 레지스트리는 딕셔너리로 정의돼 있으며 에이전트 이름으로 클래스를 접근할 수 있도록 도와준다. |  
| `base.py`	          | 최상위 베이스 클래스인 `Savable`, `VariableSource`과 네트워크와 학습자의 베이스 클래스인 `Network`, `Learner`가 정의돼 있다. |  
| `actor.py`	          | 액터의 베이스 클래스인 `Actor`가 정의돼 있다. |  
| `agent.py`	          | 에이전트의 베이스 클래스인 `Agent`가 정의돼 있다.|  

##  2. 클래스
에이전트 관련 클래스 구성은 다음과 같다.

![Agent 클래스 구성도](img/class_diagram.png)

최상위 베이스 클래스는 다음과 같은 역할을 한다.
* [`VariableSource`](VariableSource.md): 네트워크의 상태(파라미터와 버퍼)를 제공하는 인터페이스 제공
* [`Savable`](Savable.md): 네트워크의 체크포인트를 저장하고 로딩하는 인터페이스 제공
* `nn.Module`: `PyTorch` 신경망 모듈의 베이스 클래스
그리고 이들을 상속받아서 에이전트를 구성하기 위한 네 가지 베이스 클래스 `Agent`, `Learner`, `Network`와 `Actor`가 정의된다.
* [`Agent`](agent.md): 에이전트의 베이스 클래스로 ➊ 네트워크, 데이터셋, 학습자를 생성하고 ➋ 액터와 데이터셋 및 네트워크를 동기화하기 위한 인터페이스와 ➌ 학습자의 인터페이스를 제공 
* [`Actor`](actor.md): 에이전트를 대리해 환경과의 상호작용을 수행하는 액터의 베이스 클래스
* [`Learner`](learner.md): 정책을 평가하고 개선하기 위한 학습자의 베이스 클래스
* [`Network`](network.md): 정책과 가치함수 모델을 통합적으로 관리하는 네트워크의 베이스 클래스

## 3. 강화학습 알고리즘
| 구분                                            | 강화학습 알고리즘의 종류                                    | 
|:------------------|:-------------------------------------------------|
| 정책 기반  | [REINFORCE 알고리즘](reinforce/README.md)	           |  
| 정책 기반  | [REINFORCE 베이스라인 적용 알고리즘](reinforce_b/README.md) |  
| 액터-크리틱| [A2C 알고리즘](a2c/README.md)	                       |  
| 가치 기반  | [DQN 알고리즘](dqn/README.md)	                       |  
| 가치 기반  | [DDQN 알고리즘](ddqn/README.md)	                     |
| 정책 기반  | [PPO 알고리즘](ppo/README.md)	                    |